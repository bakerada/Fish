{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "from skimage import io\n",
    "from skimage import transform as tr\n",
    "from skimage import exposure as ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "\n",
    "\n",
    "def clipped_zoom(img, zoom_factor, **kwargs):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # width and height of the zoomed image\n",
    "    zh = int(np.round(zoom_factor * h))\n",
    "    zw = int(np.round(zoom_factor * w))\n",
    "\n",
    "    # for multichannel images we don't want to apply the zoom factor to the RGB\n",
    "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
    "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
    "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
    "\n",
    "    # zooming out\n",
    "    if zoom_factor < 1:\n",
    "        # bounding box of the clip region within the output array\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "        # zero-padding\n",
    "        out = np.zeros_like(img)\n",
    "        out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
    "\n",
    "    # zooming in\n",
    "    elif zoom_factor > 1:\n",
    "        # bounding box of the clip region within the input array\n",
    "        top = (zh - h) // 2\n",
    "        left = (zw - w) // 2\n",
    "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
    "        # `out` might still be slightly larger than `img` due to rounding, so\n",
    "        # trim off any extra pixels at the edges\n",
    "        trim_top = ((out.shape[0] - h) // 2)\n",
    "        trim_left = ((out.shape[1] - w) // 2)\n",
    "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
    "\n",
    "    # if zoom_factor == 1, just return the input array\n",
    "    else:\n",
    "        out = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagedir = '/home/abake116/Fish/test_stg1/'\n",
    "modelFullPath = '/home/abake116/Fish/models/inc_retrain_full/output_graph.pb'\n",
    "labelsFullPath = '/home/abake116/Fish/models/inc_retrain_full/output_labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = glob.glob(imagedir + '*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = ['image','alb','bet','dol','lag','nof','other','shark','yft']\n",
    "df = pd.DataFrame(np.nan, index=(range(len(images))),columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "    \"\"\"Creates a graph from saved GraphDef file and returns a saver.\"\"\"\n",
    "    # Creates graph from saved graph_def.pb.\n",
    "    with tf.gfile.FastGFile(modelFullPath, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_inference_on_image(image_data):\n",
    "    \n",
    "    answer = {'alb':0,'bet':0,'dol':0,'lag':0,'nof':0,'other':0,'shark':0,'yft':0}\n",
    "    #if not tf.gfile.Exists(imagePath):\n",
    "    #    tf.logging.fatal('File does not exist %s', imagePath)\n",
    "    #    return answer\n",
    "    image_data = tf.gfile.FastGFile(image_data, 'rb').read()\n",
    "\n",
    "    # Creates graph from saved GraphDef.\n",
    "    create_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "        predictions = sess.run(softmax_tensor,\n",
    "                               {'DecodeJpeg/contents:0': image_data})\n",
    "        predictions = np.squeeze(predictions)\n",
    "\n",
    "        top_k = predictions.argsort()[-8:][::-1]  # Getting top 5 predictions\n",
    "        f = open(labelsFullPath, 'rb')\n",
    "        lines = f.readlines()\n",
    "        labels = [str(w).replace(\"\\n\", \"\") for w in lines]\n",
    "        for node_id in top_k:\n",
    "            human_string = labels[node_id]\n",
    "            score = predictions[node_id]\n",
    "            answer[human_string] = score\n",
    "    \n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 0\n",
      "/home/abake116/Fish/test_stg1/img_06332.jpg\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "{'yft': 0.2761060893535614, 'shark': 0.087264999747276306, 'other': 0.069349810481071472, 'dol': 0.011138921603560448, 'nof': 0.34324482083320618, 'lag': 0.0029978067614138126, 'alb': 0.11516117304563522, 'bet': 0.094736374914646149}\n",
      "image 1\n",
      "/home/abake116/Fish/test_stg1/img_05882.jpg\n",
      "iteration 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-f60d51bc0be2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'augmented.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_inference_on_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'augmented.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-36bdba44563e>\u001b[0m in \u001b[0;36mrun_inference_on_image\u001b[0;34m(image_data)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msoftmax_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final_result:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         predictions = sess.run(softmax_tensor,\n\u001b[0;32m---> 16\u001b[0;31m                                {'DecodeJpeg/contents:0': image_data})\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abake116/anaconda/envs/tf/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abake116/anaconda/envs/tf/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abake116/anaconda/envs/tf/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/abake116/anaconda/envs/tf/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abake116/anaconda/envs/tf/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Fix this is batch predictions\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    for i,img in enumerate(images):\n",
    "        print \"image {}\".format(i)\n",
    "        print img\n",
    "        for a in range(4):\n",
    "            print 'iteration {}'.format(a)\n",
    "            image_data = io.imread(img)\n",
    "            image_data = clipped_zoom(image_data,np.random.uniform(low=1, high=1.5))\n",
    "            image_data = tr.rotate(image_data,180)\n",
    "            image_data = ex.adjust_gamma(image_data, np.random.uniform(low=0.5, high=1.5))\n",
    "            \n",
    "            #afine_tf = tr.AffineTransform(shear=np.random.uniform(low=-0.3, high=0.3))\n",
    "            #image_data = tr.warp(image_data, afine_tf)\n",
    "            io.imsave('augmented.jpg',image_data)\n",
    "            with tf.Graph().as_default():\n",
    "                answer = run_inference_on_image('augmented.jpg')\n",
    "            if a == 0:\n",
    "                final = answer\n",
    "            else:\n",
    "                for itm in final:\n",
    "                    final[itm] += answer[itm]\n",
    "        for itm in final:\n",
    "            final[itm] /= 4\n",
    "        filename = os.path.basename(img)\n",
    "        df['image'].iloc[i] = filename\n",
    "        print final\n",
    "        for x in answer:\n",
    "            df[x].iloc[i] = final[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>alb</th>\n",
       "      <th>bet</th>\n",
       "      <th>dol</th>\n",
       "      <th>lag</th>\n",
       "      <th>nof</th>\n",
       "      <th>other</th>\n",
       "      <th>shark</th>\n",
       "      <th>yft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_06332.jpg</td>\n",
       "      <td>0.095372</td>\n",
       "      <td>0.077488</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.359627</td>\n",
       "      <td>0.048093</td>\n",
       "      <td>0.122323</td>\n",
       "      <td>0.287408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_05882.jpg</td>\n",
       "      <td>0.162137</td>\n",
       "      <td>0.018784</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.125946</td>\n",
       "      <td>0.020639</td>\n",
       "      <td>0.048369</td>\n",
       "      <td>0.035111</td>\n",
       "      <td>0.587392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_03527.jpg</td>\n",
       "      <td>0.180120</td>\n",
       "      <td>0.110474</td>\n",
       "      <td>0.292287</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>0.102671</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>0.073560</td>\n",
       "      <td>0.227299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_01618.jpg</td>\n",
       "      <td>0.377978</td>\n",
       "      <td>0.085529</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.071644</td>\n",
       "      <td>0.261149</td>\n",
       "      <td>0.122199</td>\n",
       "      <td>0.018312</td>\n",
       "      <td>0.059026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_02625.jpg</td>\n",
       "      <td>0.089663</td>\n",
       "      <td>0.030610</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.036608</td>\n",
       "      <td>0.175624</td>\n",
       "      <td>0.427981</td>\n",
       "      <td>0.055331</td>\n",
       "      <td>0.182509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image       alb       bet       dol       lag       nof     other  \\\n",
       "0  img_06332.jpg  0.095372  0.077488  0.007811  0.001880  0.359627  0.048093   \n",
       "1  img_05882.jpg  0.162137  0.018784  0.001621  0.125946  0.020639  0.048369   \n",
       "2  img_03527.jpg  0.180120  0.110474  0.292287  0.007486  0.102671  0.006103   \n",
       "3  img_01618.jpg  0.377978  0.085529  0.004163  0.071644  0.261149  0.122199   \n",
       "4  img_02625.jpg  0.089663  0.030610  0.001672  0.036608  0.175624  0.427981   \n",
       "\n",
       "      shark       yft  \n",
       "0  0.122323  0.287408  \n",
       "1  0.035111  0.587392  \n",
       "2  0.073560  0.227299  \n",
       "3  0.018312  0.059026  \n",
       "4  0.055331  0.182509  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('test_aug_4.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
